---
title: 第一章 统计学习方法概论
categories:
  - machine learning
date: 2017-5-24 9:11:22
tags:
mathjax: true
---

## 1\.1 统计学习

**统计学习(statistical learning)**是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也被称为**统计机器学习**。

**统计学习的主要特点**:  
1\. 统计学习以计算机及网络为平台，是建立在计算机及网络之上的;  
2\. 统计学习以数据为研究对象，是数据驱动的学科;  
3\. 统计学习的目的是对数据进行预测与分析;  
4\. 统计学习方法以方法为中心，统计学习方法构建模型并应用模型进行预测与分析;  
5\. 统计学习是概率论、统计学习、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论。

统计学习由监督学习(supervised learning)、非监督学习(unsupervised learning)、半监督学习(semi-supervised learning)和强化学习(reinforcement learning)等组成。

本文主要讨论**监督学习**，对应的统计学习方法概括如下：从给定的、有限的、用于学习的**训练数据(training data)集合**出发，假设数据是独立同分布产生的；并且假设要学习的模型是某个函数的集合，称为**假设空间(hypothesis space)**；应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优的模型，使它对已知训练数据和未知测试数据(testing data)在给定的评价准则下有最优的预测；最优模型的选取由算法实现。  
这样，统计学习方法包括模型的**假设空间**、**模型选择的准则**以及模型学习的算法，称其为统计学习方法的三要素，简称为**模型(model)**、**策略(strategy)**和**算法(algorithm)**。

实现统计学习方法的步骤如下：  
(1) 得到一个有限的数据训练集合;  
(2) 确定包含所有可能的模型的假设空间，即学习模型的集合;  
(3) 确定模型选择的准则，即学习的策略;  
(4) 实现求解最优模型的算法，即学习的算法;  
(5) 通过学习方法选择最优模型;  
(6) 利用学习的最优模型对新数据进行预测或分析。

## 1\.2 监督学习

**监督学习(supervised learning)**的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测(注意，这里的输入、输出是指某个系统的输入输出，与学习的输入输出不同)。

### 1\.2.1 基本概念

#### 1\. 输入空间、特征空间与输出空间

在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间(input space)与输出空间(output space)。二者可以是有限元素的空间，也可以是整个欧式空间，可以是同一个空间，也可以是不同的空间，但通常输出空间远小于输入空间。

每个具体的输入是一个实例(instance)，通常由特征向量(feature vector)表示。这时，所有特征向量存在的空间称为特征空间(feature space)。特征空间的每一维对应一个特征。有时假设输入空间与特征空间为相同的空间，对它们不予区分，有时假设二者是不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。

监督学习从训练样本数据(training data)集合中学习模型，对测试数据(test data)进行预测。训练数据由输入(或特征向量)与输出对组成，训练集通常表示为 $$T=\lbrace(x_1, y_1),(x_2, y_2),...,(x_N, y_n)\rbrace$$ 测试数据也由相应的输入与输出对组成。输入与输出对又称为**样本(sample)**或样本点。

输入变量与输出变量均为连续变量的预测问题称为**回归问题**;  
输出变量为有限个离散变量的预测问题称为*分类问题*;  
输入变量与输出变量均为变量序列的预测问题称为标注问题。

#### 2\. 联合概率分布

监督学习假设输入与输出的随机变量$X$和$Y$遵循联合概率分布$P(X,Y)$。$P(X,Y)$表示分布函数，或布密度函数。注意，在学习过程中，假设这一联合概率分布存在，但对于学习系统来说，联合概率分布的具体定义是未知的。训练数据与测试数据被看作是依联合概率分布$P(X,Y)$独立同分布产生的。

统计学习假设数据存在一定的统计规律，**$X$和$Y$具有联合概率分布的假设就是监督学习关于数据的基本假设**。

#### 3\. 假设空间

监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到最好的这样的模型。模型属于由输入空间到输出空间的映射的集合，此集合即为**假设空间(hypothesis space)**。假设空间的确定意味着学习范围的确定。

监督学习的模型可以概率模型或非概率模型，由条件概率分布$P(Y|X)$或决策函数(decision function) $Y=f(X)$表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作$P(y|x)$或$y=f(x)$。

### 1\.2.2问题的形式化

监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测(prediction)。由于在这个过程中需要训练数据集，而训练数据集往往是人工给出的，所以称为监督学习。

监督学习分为**学习**和**预测**两个过程，由学习系统与预测系统完成:

![监督学习问题][1]

首先给定一个训练数据集 $$T=\lbrace(x_1, y_1),(x_2, y_2),...,(x_N, y_n)\rbrace$$

其中$(x_i, y_i), i=1,2,...,N$，称为样本或样本点。$x\in \mathcal{X}\subseteq R^n$是输入观测值，也称为输入或实例，$y_i\in \mathcal{Y}$是输出的观测值，也称为输出。

在学习过程中，学习系统利用给定的训练数据集，通过学习(或训练)得到一个模型，表示为条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$。条件概率分布$\hat{P}(Y|X)$或决策函数$Y=\hat{f}(X)$描述输入与输出随机变量之间的映射关系。

在预测过程中，预测系统对于给定的测试样本集中的输入$x_{N+1}$，由模型 $y_{N+1}=\underset{y_{N+1}}{\arg\max} \hat{P}(y_{N+1}|x_{N+1})$ 或$y_{N+1}=\hat{f}(x_{N+1})$给出相应的输出$y_{N+1}$

对于输入$x_i$，一个具体的模型$y=f(x)$可以产生一个输出$f(x_i)$，而训练数据集中对应的输出是$y_i$，如果这个模型有很好的预测能力，训练样本输出$y_i$和模型输出$f(x_i)$之间的差就应该足够小。学习系统通过不断尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时，对未知的测试数据集的预测也有尽可能好的推广。

## 1\.3 统计学习三要素

统计学习方法都由模型、策略和算法构成的，即统计学习方法由三要素构成，可以简单地表示为:  
**方法=模型+策略+算法**

下面讨论监督学习中的统计学习三要素。非监督学习、强化学习也同样拥有这三要素。

### 1\.3.1 模型

在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间(hypothesis space)包含所有可能的条件概率分布或决策函数。如，假设决策函数是输入变量的线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合。假设空间中的模型一般有无穷多个。

假设空间一般用$\mathcal{F}$表示。假设空间可以定义为决策函数的集合。 $$\mathcal{F}=\lbrace f|Y=f(X)\rbrace$$ 其中，$X$和$Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的变量。这时$\mathcal{F}$通常是由一个参数向量决定的函数簇： $$\mathcal{F}=\lbrace f|Y=f_\theta (X), \theta \in R^n\rbrace$$ 参数向量$\theta$取值于$n$维欧氏空间$R^n$，称为**参数空间(parameter space)**。

假设空间也可以定义为条件概率的几何

$$\mathcal{F}=\lbrace P|P(Y|X)\rbrace$$ 其中，$X$和$Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的随机变量。这时$\mathcal{F}$通常是由一个参数向量决定的条件概率分布簇 $$\mathcal{F}=\lbrace P|P_\theta (Y|X), \theta \in R^n$$ 参数向量$\theta$取值于$n$维欧氏空间$R^n$，也称为参数空间。

本书称由决策函数表示的模型为非概率模型，由条件概率表示的模型为概率模型。为了简便起见，当论及模型时，有时只用其中一种模型。

### 1\.3.2 策略

有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。统计学习的目标在于从假设空间中选取最优模型。

#### 1\. 损失函数(loss fucntion)和风险函数(risk function)

监督学习问题是在假设空间$\mathcal{F}$中选取模型$f$作为决策函数，对于给定的输入$X$，由$f(X)$给出相应的输出$Y$，这个输出的预测值$f(X)$与真实值$Y$可能一致也可能不一致，用一个**损失函数(loss function)**或**代价函数(cost function)**来度量预测错误的程度。损失函数是$f(X)$和$Y$和非负实值函数，记作$L(Y,f(X))$。

统计学习中常用的损失函数有：  
(1) **0-1 损失函数(0-1 loss function)** \begin{eqnarray} L(Y,f(X))= \begin{cases} 1,& \mbox{$Y\neq f(X)$ } \newline 0, &\mbox{$Y=f(X)$ } \end{cases} \end{eqnarray}

(2) **平方损失函数(quadratic loss function)**  
$$L(Y,f(X))=(Y-f(X))^2$$

(3) **绝对损失函数(absolute loss function)**  
$$L(Y,f(X))=|Y-f(X)|$$

(4) **对数损失函数(logarithmic loss function)或对数似然损失函数(log-likehood loss function)**  
$$L(Y, f(X))=-logP(Y|X)$$

> **联合概率分布** 随机变量X和Y的联合分布函数是设(X,Y)是二维随机变量，对于任意实数x,y，二元函数： $F(x,y) = P(X\leq x, Y\leq y)$ 称为二维随机变量$(X,Y)$的分布函数。
> 
> **几何意义** 如果将二维随机变量$(X,Y)$看成是平面上随机点的坐标，那么分布函数$F(x,y)$在$(x,y)$处的函数值就是随机点$(X,Y)$落在以点$(x,y)$为顶点而位于该点左下方的无穷矩形域内的概率。

损失函数值越小，模型就越好。由于模型的输入、输出$(X, Y)$是随机变量，遵循联合概率分布$P(X,Y)$，故损失函数的期望是  
$$R_{exp}(f) = E_p [L(Y, f(X))] = \int_{\mathcal{X}\times\mathcal{Y}} L(y, f(x))P(x, y)dxdy$$

这是理论上模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失，称为**风险函数(risk function)**或**期望损失(expected loss)**。

学习的目标就是选择期望风险最小的模型。由于联合分布$P(X, Y)$是未知的，$R_{exp}(f)$不能直接计算。实际上，如果知道联合分布$P(X,Y)$，可以从联合分布直接求出条件概率分布$P(Y|X)$，也就不需要学习了。正因为不知道联合概率分布，所以才需要学习。这样一来，一方面根据期望风险最小学习模型要用到联合概率分布，另一方面联合分布又是未知的，所以监督学习就成为了一个**病态问题(ill-formed problem)**。

给定一个训练数据集 $$T=\lbrace (x_1, y_1), (x_2, y_2), ..., (x_N, y_N)$$ 模型$f(X)$关于训练数据集的平均损失称为**经验风险(empirical risk)**或**经验损失(empirical loss)**，记作$R_{emp}$:  
$$R_{emp}(f) = \frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i))$$ 期望风险$R_{emp}(f)$是模型关于联合分布的期望损失，经验风险$R_{emp}(f)$是模型关于训练样本集的平均损失。根据大数定律，当样本容易$N$趋于无穷大时，经验风险函数$R_{emp}$趋于期望风险函数$R_{exp}$。故一个自然的想法是用经验风险估计期望风险。但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险，常常并不理想，要对经验风险进行一定的矫正。这就关系到监督学习的两个基本策略：**经验风险最小化**和**结构风险最小化**。

#### 2\. 经验风险最小化与结构风险最小化

在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定。**经验风险最小化(empirical risk minimization, ERM)**的策略认为，经验风险最小的模型是最优的模型。根据这一策略，按照经验风险最小化求最优模型就是求解最优化问题：  
$$\underset{f\in \mathcal{F}}{\min}\frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i))$$ 其中，$\mathcal{F}$是假设空间。

当样本容量很大时，经验风险最小化能保证有很好的学习效果，在现实中被广泛采用。

但当样本容量很小时，经验风险最小化学习的效果就未必很好，会产生“过拟合”现象。

**结构风险最小化(structural risk minimization, SRm)**是为了防止过拟合而提出来的策略。结构风险最小化等价于**正则化(regularization)**。结构风险在经验风险上加上表示模型复杂度的**正则化项(regularizer)**或**罚项(penalty term)**。

在假设空间、损失函数以及训练数据确定的情况下，结构风险的定义是: $$R_{srm}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i))+\lambda J(f)$$ 其中$J(f)$为模型的复杂度，是定义在假设空间$\mathcal{F}$上的泛函。模型$f$越复杂，复杂度$J(f)$就越大;反之，模型$f$越简单，复杂度$J(f)$就越小。即复杂度表示了复杂模型的惩罚。$\lambda\geq0$是系数，用以权衡经验风险和模型复杂度。结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。

结构风险最小的策略认为结构风险最小的模型是最优的模型。所以求最优模型，就是求解最优化问题： $$\underset{f\in\mathcal{F}}{\min}\frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i))+\lambda J(f)$$

这些，监督学习问题就变成了经验风险或结构风险函数的最优化问题。这时经验或结构风险函数是最优化的目标函数。

### 1\.3.3 算法

算法是指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。

这时，统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法。如果最优化问题有显示的解析解，这个最优化问题就比较简单。但通常解析解不存在，这就需要用数值计算的方法求解。

统计学习方法之间的不同，主要来自其模型、策略、算法的不同。确定了模型、策略、算法，统计学习的方法也就确定了。这也就是将其称为统计学习三要素的原因。

## 1\.4 模型评估与模型选择

### 1\.4.1 训练误差与测试误差

当损失函数给定时，基于损失函数的模型的训练误差(training error)和模型的测试误差(test error)就自然成为学习方法评估的标准。注意，统计学习方法具体采用的损失函数未必是评估时使用的损失函数。当然，让两者一致是比较理想的。

假设学习到的模型是$Y=\hat{f}(X)$，**训练误差**是模型$Y=\hat{f}(X)$关于训练数据集的平均损失： $$R_{emp}(\hat{f})=\frac{1}{N}\sum_{i=1}^{N}L(y_i,\hat{f}(x_i))$$ 其中$N$是训练样本容量。

**测试误差**是模型$Y=\hat{f}(X)$关于测试数据集的平均损失： $$e_{test}=\frac{1}{N}\sum_{i=1}^{N'}L(y_i, \hat{f}(x_i))$$ 其中$N'$是测试样本容量。

当损失函数是0-1损失时，测试误差就变成了常见的测试数据集上的**误差率(error rate)** $$e_{test}=\frac{1}{N}\sum_{i=1}^{N'}L(y_i != \hat{f}(x_i))$$ 这里$I$是指示函数(indicator function)，即$y\neq \hat{f}(x)$时为1，否则为0.

相应地，常见的测试数据集上的**准确率(accuracy)**为 $$r_{test}=\frac{1}{N'}\sum_{i=1}^{N'}I(y_i=\hat{f}(x_i))$$ 显然， $$r_{test} + e_{test} = 1$$

训练误差的大小，对判断给定的问题是不是一个容易学习的问题是有意义的，但本质上不重要。测试误差反映了学习方法对未知的测试数据集的预测能力，是学习中的重要概念。显然，给定两种学习方法，测试误差大小的方法具有更好的预测能力，是更有效的方法。通常将学习方法对未知数据的预测能力称为**泛化能力(generalization ability)**。

### 1\.4.2 过拟合与模型选择

当假设空间含有不同复杂度(例如，不同的参数个数)的模型时，就要面临模型(model selection)选择的问题。若在假设空间存在“真”模型，那么所选择的模型应该逼近真模型。具体地，所选择的模型要与真模型的参数个数相同，所选择的模型的参数向量与真模型的参数向量相近。

若一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合(over-fitting)。过拟合是指学习时选择的模型所包含的参数过多，以致于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。

模型选择旨在避免过拟合并提高模型的预测能力。

当模型的复杂度增大时，训练误差会逐渐减小并趋于0;而测试误差会先减小，达到最小值后又增大。当选择的模型复杂度过大时，过拟合现象就会发生。这样，在学习时就要防止过拟合，进行最优化的模型选择，即选择复杂度适当的模型，以达到测试误差最小的学习目的。 ![训练误差和测试误差与模型复杂度的关系][2]

## 1\.5 正则化与交叉验证

### 1\.5.1 正则化

模型选择的典型方法是**正则化(regularization)**。正则化是结构风险最小化策略的实现，是在经验风险上加一个**正则化项(regularizer)**或**罚项(penalty term)**。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如，正则化项可以是模型参数向量的范数。

正则化项一般具有如下形式： $$\underset{f\in\mathcal{F}}{\min}\frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i))+\lambda J(f)$$

正则化项符合**奥卡姆剃刀(Occam's razor)原理**。

### 1\.5.2 交叉验证

另一种常用的模型选择方法是**交叉验证(cross validation)**。

若给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分别为**训练集(training set)**、**验证集(validation set)**和**测试集(test set)**。训练集用来训练模型，验证集用于模型的选择，而测试集用于最终对学习方法的评估。在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。由于验证集有足够多的数据，用它对模型进行选择也是有效的。

但是，在许多实际应用中数据是不充足的，为了选择好的模型，可以采用交叉验证方法。交叉验证的基本想法是重复地使用数据;把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。

#### 1\. 简单交叉验证

简单交叉验证方法是：首先随机地将已经数据分为两部分，一部分作为训练集，另一部分作为测试集；然后用训练集在各种条件下(例如，不同的参数个数)训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。

#### 2\. S折交叉验证

应用最多的是**S折交叉验证(S-fold cross validation)**，方法如下：首先随机地将已给数据切分为S个互不相交的大小相同的子集；然后利用$S-1$个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S种选择重复进行；最后选出S次评测中平均测试误差最小的模型。

#### 3\. 留一交叉验证

S折交叉验证的特殊情形是$S=N$，称为留一交叉验证(leave-one-out cross validation)，往往在数据缺乏的情况下使用。这里，$N$是给定数据集的容量。

## 1\.6 泛化能力

### 1\.6.1 泛化误差

学习方法的泛化能力(generalization ability)是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力。但这种评价是依赖于测试数据集的。因为测试数据集是有限的，很有可能由此得到的评价结果是不可靠的。统计学习理论试图从理论上对学习方法的泛化能力进行分析。

若学到的模型是$\hat{f}$，则用这个模型对未知数据预测的误差即为泛化误差(generalization error) $$R_{exp}(\hat{f})=E_{P}[L(Y,\hat{f}(X))]=\int_{\mathcal{X}\times\mathcal{Y}}L(y,\hat{f}(x))P(x,y)dxdy$$ 泛化误差反映了学习方法的泛化能力，若一种方法学习的模型比另一种方法学习的模型具有更小的泛化误差，则这种方法就更有效。事实上，泛化误差就是所学习到的模型的期望风险。

### 1\.6.2 泛化误差上界

学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称为**泛化误差上界(generalization error bound)**。就是通过比较两种学习方法的泛化误差上界的大小来比较它们的优劣。

泛化误差上界通常具有以下性质：它是样本容量的函数，当样本容量增加时，泛化上界趋于0；它是假设空间容量(capacity)的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大。

## 生成模型与判别模型

监督学习方法又可以分为**生成方法(generative approach)**和**判别方法(discriminative approach)**。所学到的模型分别称为**生成模型(generative model)**和**判别模型(discriminative model)**。

**生成方法**由数据来学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为**预测的模型**，即**生成模型**： $$P(X|Y)=\frac{P(X,Y)}{P(X)}$$ 这样的方法之所以称为生成方法，是因为模型表示了给定输入$X$产生输出$Y$的生成关系。

典型的生成模型有：**朴素贝叶斯法**和**隐马尔可夫模型**。

判别方法由数据直接学习决策函数$f(X)$或者条件概率分布$P(Y|X)$作为预测模型，即判别模型。判别方法关心的是对给定的输入$X$，应该预测什么样的输出$Y$。典型的判别模型包括：**$k$近邻法、感知机、决策树、逻辑斯谛回归模型、最大熵模型、支持向量机、提升方法和条件随机场**等。

生成方法的特点：生成方法可以还原出联合概率分布$P(X,Y)$，而判别方法则不能；生成方法的学习收敛速度更快，即当样本容量增加时，学到的模型可以更快地收敛于真实模型；当存在隐变量时，仍可以用生成方法学习，而不能使用判别方法了。

判别方法的特点：判别方法直接学习的是条件概率$P(Y|X)$或决策函数$f(X)$，直接面对预测，往往学习的准确率更高；由于直接学习$P(Y|X)$或$f(X)$，可以对数据进行各种程度上的抽象、定义特征并使用特征。

## 1\.8 分类问题

在监督学习中，当输出变量$Y$取有限个离散值时，预测问题便成为分类问题。

监督学习从数据中学习一个分类模型或分类决策函数，称为**分类器(classifier)**。分类器对新的输入进行输出的**预测(prediction)**，称为**分类(classification)**。可能的输出称为**类(class)**。分类的类别为多个时，称为多分类问题。

![分类问题][3]

评价分类器性能的指标一般是分类**准确率(accuracy)**：对于给定的测试数据集，分类器正确分类的样本数与总样本数的比。

对于二分类问题常用的评价指标是**精确率(precision)**与**召回率(recall)**。  
通常以关注的类为**正类(positive)**，其他类为**负类(negative)**，分类器在测试数据集上的预测或正确或不正确，4种情况出现的**总数**分别记作：  
**TP** : 将正类预测为正类的个数；  
**FN** : 将正类预测为负类的个数；  
**FP** : 将负类预测为正类的个数；  
**TN** : 将负类预测为负类的个数；

**精确率**定义为 $$P=\frac{TP}{TP+FP}$$ **召回率**定义为 $$R=\frac{TP}{TP+FN}$$

$F_1$值，是精确率和召回率的调和值，即 $$\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}$$ $$F_1=\frac{2TP}{2TP+FP+FN}$$ 精确率和召回率都高时，$F_1$值也会高。

许多统计学习的方法可以用于分类，包括k近邻法、感知机、朴素贝叶斯法、决策树、决策列表、逻辑斯谛回归模型、支持向量机、提升方法、贝叶斯网络、神经网络、Winnow等。

## 1\.9 标注问题

**标注(taggin)**也是一个监督学习问题。可以认为标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测(structure prediction)问题的简单形式。标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。

![标注问题][4]

标注常用的统计学习方法：隐马尔可夫模型、条件随机场。

## 1\.10 回归问题

**回归(regression)**是监督学习的另一个重要问题。回归用于预测**输入变量(自变量)**和**输出变量(因变量)**之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。回归模型正是从输入变量到输出变量之间映射的函数。回归问题的学习等价于函数拟合：选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据。

![回归问题][5]

回归问题按照输入变量的个数，分为一元回归和多元回归；按输入变量和输出变量之间的关系类型即模型的类型，分为线性回归和非线性回归。

回归问题最常用的损失函数是平方损失函数，在此情况下，回归问题可以由最著名的**最小二乘法(least squares)**求解。

 [1]: http://oqfqjieze.bkt.clouddn.com/blog/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98.png
 [2]: http://oqfqjieze.bkt.clouddn.com/blog/model_complexity.png
 [3]: http://oqfqjieze.bkt.clouddn.com/classification_problem.png
 [4]: http://oqfqjieze.bkt.clouddn.com/tagging_problem.png
 [5]: http://oqfqjieze.bkt.clouddn.com/huigui_problem.png